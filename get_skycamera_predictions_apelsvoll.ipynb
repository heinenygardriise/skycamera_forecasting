{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skycamera not up to date\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heinenr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\heinenr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\heinenr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.21.2 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\heinenr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.21.2 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_horizon (min)   1    2    3    4    5    6    7    8    9    10  \\\n",
      "date_time                                                                    \n",
      "2019-07-16 21:29:00       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "prediction_horizon (min)  ...   21   22   23   24   25        26   27   28  \\\n",
      "date_time                 ...                                                \n",
      "2019-07-16 21:29:00       ...  0.0  0.0  0.0  0.0  0.0  0.150538  0.0  0.0   \n",
      "\n",
      "prediction_horizon (min)       29   30  \n",
      "date_time                               \n",
      "2019-07-16 21:29:00       2.66622  0.0  \n",
      "\n",
      "[1 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_skycamera_predictions_apelsvoll():\n",
    "    import pandas as pd\n",
    "\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    import os\n",
    "    import time as t\n",
    "\n",
    "    import datetime\n",
    "    import pvlib\n",
    "    from pvlib.location import Location\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    import mysql.connector # lastes ned ved 'pip install mysql' i command promt\n",
    "    from load_snowdata import load_snowdata_apelsvoll\n",
    "    import sys\n",
    "\n",
    "    sys.path.append(r'C:\\Users\\heinenr\\Documents\\git_local\\twin_tools\\\\')\n",
    "\n",
    "    from twin_tools import get_statistical_twin, remove_outliers, sort_split_dfs\n",
    "\n",
    "    import pickle\n",
    "\n",
    "    def get_cloud_map(frame, method='brd_ref'):\n",
    "        \"\"\"Takes an RGB-image (numpy-array) and transforms to a cloud map through a image algorithm and naive thresholding\"\"\"\n",
    "\n",
    "        if method=='brd_ref':\n",
    "            r_ref = np.mean(frame[:, :, 2]) # defining mean red value for polar converted image\n",
    "            b_ref = np.mean(frame[:, :, 0]) # defining mean blue value for polar converted image\n",
    "\n",
    "            cloud_map = np.subtract((frame[:, :, 0]-b_ref), (frame[:, :, 2]-r_ref)).astype(np.uint8)           \n",
    "\n",
    "            cloud_map[cloud_map<(np.mean(cloud_map))]=0\n",
    "            cloud_map[cloud_map>(np.mean(cloud_map))]=255\n",
    "        else:\n",
    "            frame=None\n",
    "            print('Model not recognized. Valid models are brd_ref')\n",
    "        return cloud_map\n",
    "\n",
    "    def corners_inside_sun(speed_ave, angle_ave, good_corners, cloud_map, location, prediction_horizon, resize_dim, frames_per_min=2):    \n",
    "        inside = []\n",
    "\n",
    "\n",
    "        predicted_point = np.zeros_like(good[-1])\n",
    "\n",
    "        num_frames=prediction_horizon*frames_per_min #how many frames into the future to predict\n",
    "        displacement_x = num_frames*speed_ave*np.cos(angle_ave)\n",
    "        displacement_y = num_frames*speed_ave*np.sin(angle_ave)\n",
    "        predicted_point[:,0], predicted_point[:,1] = (good_corners[-1][:,0] + displacement_x), (good_corners[-1][:,1] + displacement_y)\n",
    "\n",
    "        prediction_time = time + pd.Timedelta(prediction_horizon, unit='min')\n",
    "\n",
    "        #get the solar position in the location and times specified\n",
    "        solpos = location.get_solarposition(prediction_time)\n",
    "        rho = resize_dim/2\n",
    "\n",
    "        # cylindrical\n",
    "        r = rho*np.sin(np.radians(solpos['apparent_zenith']))\n",
    "        azimuth = np.radians(solpos['azimuth']) + (9*np.pi/16) # camera is rotated approx 10 degs, so a correction factor of pi/16 is needed (specific for apelsvoll). pi/2 is added to rotate image so that 0 is north. \n",
    "\n",
    "        #fisheye distortion\n",
    "        r_norm = r/rho\n",
    "\n",
    "        r_dist_norm = 2*(r_norm + (1-np.sqrt(1 -r_norm**2))/2)/3 #must divide the normal fisheye formula by 1.5. Don't know why\n",
    "        r_dist = r_dist_norm*rho\n",
    "\n",
    "        # to cartesian (and adjusting to fit picture indices)\n",
    "        x_dist=r_dist*np.cos(azimuth)+rho\n",
    "        y_dist=rho-r_dist*np.sin(azimuth)\n",
    "\n",
    "        points_inside = (predicted_point[:,0]>(x_dist[0]-20))&(predicted_point[:,0]<(x_dist[0]+20))&(predicted_point[:,1]>(y_dist[0]-20))&(predicted_point[:,1]<(y_dist[0]+20))\n",
    "        points_inside_sum = points_inside.sum()\n",
    "        pixels = good_corners[-1][points_inside]\n",
    "        roi_sum = 0\n",
    "\n",
    "        if len(pixels)>0:\n",
    "            for pixel in pixels:\n",
    "                roi = cloud_map[(int(pixel[0])-20):(int(pixel[0])+20), (int(pixel[1])-20):(int(pixel[1])+20)]\n",
    "                roi_mean = np.mean(roi)\n",
    "                roi_sum += roi_mean\n",
    "                roi_ave = roi_sum/len(pixels)\n",
    "        else:\n",
    "            roi_ave=0           \n",
    "\n",
    "        inside.append([time, points_inside_sum, roi_ave])\n",
    "        columns = [[prediction_horizon], ['num_corners', 'ave_pixel_intensity']]\n",
    "\n",
    "\n",
    "        inside_df = pd.DataFrame(inside)\n",
    "        inside_df.index = inside_df.pop(0)\n",
    "        inside_df.columns = pd.MultiIndex.from_product(columns, names=['time_ahead', 'predictions'])\n",
    "\n",
    "        return inside_df, predicted_point, x_dist, y_dist\n",
    "\n",
    "    def get_clearsky_irr(times, location):\n",
    "\n",
    "        # Run functions\n",
    "        lin_turb = pvlib.clearsky.lookup_linke_turbidity(times,\n",
    "                                                         location.latitude,\n",
    "                                                         location.longitude)\n",
    "\n",
    "        cSky = location.get_clearsky(times, model='ineichen',\n",
    "                                    linke_turbidity=lin_turb)\n",
    "        solarpos = pvlib.solarposition.spa_python(times, location.latitude,\n",
    "                                                  location.longitude,\n",
    "                                                  altitude=location.altitude)\n",
    "\n",
    "        extr_terr_irr = pvlib.irradiance.get_extra_radiation(times)\n",
    "        AM = location.get_airmass(solar_position=solarpos)\n",
    "        POA_total = pvlib.irradiance.get_total_irradiance(syst_angles['tilt'],\n",
    "                                                          syst_angles['azimuth'],\n",
    "                                                          solarpos['apparent_zenith'],\n",
    "                                                          solarpos['azimuth'],\n",
    "                                                          cSky.dni, cSky.ghi, cSky.dhi,\n",
    "                                                          extr_terr_irr,\n",
    "                                                          AM.airmass_absolute,\n",
    "                                                          model='perez')\n",
    "\n",
    "        POA_total.index = range(1,times.shape[0]+1)\n",
    "        poa_trans = POA_total.transpose()\n",
    "        poa_trans.columns = pd.MultiIndex.from_product([list(POA_total.index),['clear_sky_POA']], names=['time_ahead', 'predictions'])\n",
    "        poa_trans_global = poa_trans.loc['poa_global']\n",
    "        poa_trans_global.name = time\n",
    "        poa_trans.index = [time, 'poa_direct','poa_diffuse', 'poa_sky_diffuse','poa_ground_diffuse'] # poa_global is given time-index so that it joins on the correect index with prediction_df\n",
    "        return poa_trans, POA_total\n",
    "\n",
    "    directory = r\"C:\\Users\\heinenr\\OneDrive - Institutt for Energiteknikk\\Prosjekt\\Solar Farm\\kamerabileter\\3_days_july_2019\\all_days\"\n",
    "    first_image_path = os.path.join(directory, os.listdir(directory)[-4])\n",
    "    first = cv2.imread(first_image_path, 1)\n",
    "\n",
    "    resize_dim = 600\n",
    "    max_dim = max(first.shape)\n",
    "    scale = resize_dim/max_dim\n",
    "    old_frame = cv2.resize(first, None, fx=scale, fy=scale)\n",
    "\n",
    "    black = np.zeros_like(old_frame)\n",
    "    circle = cv2.circle(black, (int(black.shape[0]/2), int(black.shape[1]/2)), int(black.shape[0]/2)-25, color=(255,255,255), thickness=-1)\n",
    "    white_mask = (cv2.cvtColor(circle, cv2.COLOR_BGR2GRAY)/255).astype(np.uint8)\n",
    "\n",
    "    old_cloud_map = get_cloud_map(old_frame)\n",
    "\n",
    "    # params for ShiTomasi corner detection\n",
    "    feature_params = dict( maxCorners = 10000,\n",
    "                           qualityLevel = 0.05,\n",
    "                           minDistance = 1,\n",
    "                           blockSize = 15 )\n",
    "\n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params = dict( winSize  = (15,15),\n",
    "                      maxLevel = 5,\n",
    "                      criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    # Create some random colors\n",
    "    color = np.random.randint(0,255,(10000,3))\n",
    "\n",
    "    # Take first frame and find corners in it\n",
    "\n",
    "    p_first = cv2.goodFeaturesToTrack(old_cloud_map, mask = white_mask, **feature_params)\n",
    "\n",
    "    # Create a mask image for drawing purposes\n",
    "\n",
    "    num_frames_integrated = 4\n",
    "    frames_per_min = 2\n",
    "\n",
    "    syst_angles = {'tilt': 46, 'azimuth': 173}\n",
    "    location = Location(60.7008333, 10.867777777777778, tz='Europe/Oslo',\n",
    "                       altitude=273, name='Apelsvoll')\n",
    "    # found from latlong.net, Østre Toten målestasjon i\n",
    "\n",
    "    all_predictions = pd.DataFrame()\n",
    "    evaluated_times = []\n",
    "\n",
    "    if os.listdir(directory)[-1][-9:-7] == '30':\n",
    "        half_minute_correction = 9\n",
    "    else:\n",
    "        half_minute_correction = 8\n",
    "\n",
    "    for image in range((len(os.listdir(directory))-half_minute_correction), len(os.listdir(directory))):\n",
    "        #start = t.time()\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            filenames = []\n",
    "\n",
    "            for name in files[image:image+num_frames_integrated]:\n",
    "                filename = os.path.join(root, name)\n",
    "                filenames.append(filename)\n",
    "\n",
    "        if len(filenames)<4:\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            p = []\n",
    "            good = []\n",
    "            speed = []\n",
    "            angle = []\n",
    "\n",
    "            f0=filenames[0]\n",
    "            mask = np.zeros_like(old_frame)\n",
    "\n",
    "\n",
    "            frame0 = cv2.imread(f0, 1)\n",
    "            frame0 = cv2.resize(frame0, None, fx=scale, fy=scale)\n",
    "\n",
    "            cloud_map0 = get_cloud_map(frame0)\n",
    "\n",
    "            p.append(cv2.goodFeaturesToTrack(cloud_map0, mask = white_mask, **feature_params))\n",
    "\n",
    "            if p[0] is None:\n",
    "                p_placeholder, st0, err = cv2.calcOpticalFlowPyrLK(old_cloud_map, cloud_map0, p_first, None, **lk_params)\n",
    "                p.append(p_placeholder)\n",
    "                # Select good points\n",
    "                good.append(np.ones_like(p_placeholder[st0==1]))\n",
    "            else:\n",
    "                p[0] = p[0].astype(np.float32)\n",
    "\n",
    "                # calculate optical flow\n",
    "                p_placeholder, st0, err = cv2.calcOpticalFlowPyrLK(old_cloud_map, cloud_map0, p[0], None, **lk_params)\n",
    "                p.append(p_placeholder)\n",
    "                good.append(p[0][st0==1])\n",
    "\n",
    "            good.append(p[1][st0==1])\n",
    "\n",
    "            speed.append(np.sqrt((good[1][:,1]-good[0][:,1])**2+(good[1][:,0]-good[0][:,0])**2))\n",
    "            angle.append(np.arctan((good[1][:,1]-good[0][:,1])/(good[1][:,0]-good[0][:,0])))\n",
    "\n",
    "            old_cloud_map = cloud_map0.copy()\n",
    "\n",
    "            for frame_num in range(2,(len(filenames))):\n",
    "\n",
    "                file=filenames[frame_num]\n",
    "\n",
    "                frame = cv2.imread(file, 1)\n",
    "                frame = cv2.resize(frame, None, fx=scale, fy=scale)\n",
    "\n",
    "                cloud_map = get_cloud_map(frame)\n",
    "\n",
    "                # calculate optical flow\n",
    "                p_placeholder, st, err = cv2.calcOpticalFlowPyrLK(cloud_map0, cloud_map, p[frame_num-1], None, **lk_params)\n",
    "                p.append(p_placeholder)\n",
    "                good.append(p[frame_num][st0==1])\n",
    "\n",
    "                speed.append(np.sqrt((good[frame_num][:,1]-good[frame_num-1][:,1])**2+(good[frame_num][:,0]-good[frame_num-1][:,0])**2))\n",
    "                angle.append(np.arctan((good[frame_num][:,1]-good[frame_num-1][:,1])/(good[frame_num][:,0]-good[frame_num-1][:,0])))\n",
    "\n",
    "                cloud_map0 = cloud_map.copy()\n",
    "\n",
    "            speed_ave = np.zeros_like(speed[0])\n",
    "            angle_ave = np.zeros_like(angle[0])\n",
    "\n",
    "            for i in range(len(speed)):\n",
    "                speed_sum = np.add(speed_ave,speed[i])\n",
    "                angle_sum = np.add(angle_ave,angle[i])\n",
    "\n",
    "            speed_ave = speed_sum/len(speed)\n",
    "            angle_ave = angle_sum/len(speed)\n",
    "\n",
    "            time = pd.to_datetime(file[-21:-7])\n",
    "            evaluated_times.append(time)\n",
    "            prediction_df = pd.DataFrame()\n",
    "            for prediction_horizon in range(1,31):\n",
    "\n",
    "                inside_df, predicted_point, x_dist, y_dist = corners_inside_sun(speed_ave, angle_ave, good, cloud_map, location, prediction_horizon, resize_dim, frames_per_min=2)\n",
    "\n",
    "                prediction_df = pd.concat([prediction_df, inside_df], axis=1)\n",
    "\n",
    "            times = pd.date_range(time+pd.Timedelta(1,unit='min'), periods=30, freq='T')\n",
    "\n",
    "            poa_trans, POA_total = get_clearsky_irr(times, location)\n",
    "            prediction_df = prediction_df.join(poa_trans).sort_index(axis=1)\n",
    "\n",
    "            # Now update the previous frame and previous points\n",
    "            all_predictions = pd.concat([all_predictions, prediction_df], axis=0)\n",
    "            p[0] = good[1].reshape(-1,1,2)\n",
    "        #stop = t.time()\n",
    "        #duration=stop-start\n",
    "        #print(duration)\n",
    "\n",
    "    cloud_number_sum = all_predictions.xs('num_corners', level='predictions', axis=1)*all_predictions.xs('ave_pixel_intensity', level='predictions', axis=1)\n",
    "    normalization_factor = np.array([52702.95375, 51618.52668103, 50534.09961207, 49449.6725431,\n",
    "           48365.24547414, 47280.81840517, 46196.39133621, 45111.96426724,\n",
    "           44027.53719828, 42943.11012931, 41858.68306034, 40774.25599138,\n",
    "           39689.82892241, 38605.40185345, 37520.97478448, 36436.54771552,\n",
    "           35352.12064655, 34267.69357759, 33183.26650862, 32098.83943966,\n",
    "           31014.41237069, 29929.98530172, 28845.55823276, 27761.13116379,\n",
    "           26676.70409483, 25592.27702586, 24507.8499569, 23423.42288793,\n",
    "           22338.99581897, 21254.56875])\n",
    "    cloud_number_norm = 1-(cloud_number_sum/normalization_factor)\n",
    "    cloud_number_norm.columns = pd.MultiIndex.from_product([list(cloud_number_norm.columns), ['weighted_cloud_number']], names=['time_ahead', 'predictions'])\n",
    "    all_predictions = all_predictions.join(cloud_number_norm).sort_index(axis=1)\n",
    "\n",
    "    predicted_irr = (all_predictions.xs('weighted_cloud_number', level='predictions', axis=1))*all_predictions.xs('clear_sky_POA', level='predictions', axis=1)\n",
    "    predicted_irr.columns = pd.MultiIndex.from_product([list(predicted_irr.columns), ['predicted_irradiance']], names=['time_ahead', 'predictions'])\n",
    "    all_predictions = all_predictions.join(predicted_irr).sort_index(axis=1)\n",
    "    all_predictions.index.name = 'date_time'\n",
    "\n",
    "    if pd.Timestamp.now()-pd.Timestamp(all_predictions.index[-1])>pd.Timedelta(1, 'T'):\n",
    "        print('Skycamera not up to date')\n",
    "\n",
    "    _user='ifePVsystem'      # brukernavn\n",
    "    _password='Sol1Sinnet'   # passord\n",
    "    _host='128.39.229.38'    # evt. kj-sol-01, dette er adressen der serveren bor, og kan bare nåes på IFEs internnett (kabel eller VPN)\n",
    "    _database='pvs'      # navnet på databasen vår. En host kan ha flere databaser (som en blokk kan ha flere leiligheter)\n",
    "\n",
    "    query1 = '''SELECT date_time, irradiance_in_plane, irradiance_horizontal, ambient_temperature, panel_t1, panel_t2, panel_t3, panel_t4\n",
    "                FROM temp_data\n",
    "                WHERE id_site = 4\n",
    "                AND (date_time BETWEEN '{0}' AND '{1}') \n",
    "                ORDER by date_time'''.format(evaluated_times[-1]-pd.Timedelta(10, unit='T'), evaluated_times[-1])\n",
    "\n",
    "    connection = mysql.connector.connect(user=_user, password=_password, host=_host, database=_database)\n",
    "    temp_data = pd.read_sql(query1, con=connection)\n",
    "    connection.close()\n",
    "\n",
    "    query2 = '''SELECT date_time, wind_min, wind_max, wind_mid  \n",
    "                FROM wind_data\n",
    "                WHERE id_site = 4\n",
    "                AND (date_time BETWEEN '{0}' AND '{1}') \n",
    "                ORDER by date_time'''.format(evaluated_times[-1]-pd.Timedelta(10, unit='T'), evaluated_times[-1])\n",
    "\n",
    "    connection = mysql.connector.connect(user=_user, password=_password, host=_host, database=_database)\n",
    "    wind_data = pd.read_sql(query2, con=connection)\n",
    "    connection.close()\n",
    "\n",
    "    query3 = '''SELECT date_time, ac_power \n",
    "                FROM inverter_data\n",
    "                WHERE id_site = 4\n",
    "                AND (date_time BETWEEN '{0}' AND '{1}') \n",
    "                ORDER by date_time'''.format(evaluated_times[-1]-pd.Timedelta(10, unit='T'), evaluated_times[-1])\n",
    "\n",
    "    connection = mysql.connector.connect(user=_user, password=_password, host=_host, database=_database)\n",
    "    inverter_data = pd.read_sql(query3, con=connection)\n",
    "    connection.close()\n",
    "\n",
    "    df_inverter = inverter_data.merge(temp_data).merge(wind_data)\n",
    "    df_inverter.index = df_inverter.date_time\n",
    "    df_inverter.drop('date_time', axis=1, inplace=True)\n",
    "    df_inverter.head()\n",
    "\n",
    "    snow_index = df_inverter.index.tz_localize('UTC').tz_convert('Europe/Oslo')\n",
    "    snow = load_snowdata_apelsvoll(str(snow_index[0].date()), str(snow_index[-1].date()+pd.Timedelta(1,unit='D'))).resample(pd.infer_freq(snow_index)).pad()[str(snow_index[0]):str(snow_index[-1])]\n",
    "    snow = snow[~snow.index.duplicated()]\n",
    "    snow.index = snow.index.tz_convert('UTC').tz_localize(None)\n",
    "    df_inverter = df_inverter.join(snow, on=df_inverter.index)\n",
    "    df_inverter = df_inverter[df_inverter['snow_depth']==0]\n",
    "    df_inverter.drop(['swe', 'snow_depth'], axis=1, inplace=True)\n",
    "\n",
    "    saveFolderName = r\"C:\\Users\\heinenr\\OneDrive - Institutt for Energiteknikk\\Jupyter Notebooks\\Prosjekt\\Solar Farm\\\\\"\n",
    "\n",
    "    pickleName = 'apelsvoll_skycamera_predictions_regressors.sav'\n",
    "    predictions = []\n",
    "    with open(saveFolderName+pickleName,\"rb\") as pickle_in:\n",
    "            regressor_dict = pickle.load(pickle_in)\n",
    "\n",
    "    for prediction_horizon in range(1,31):\n",
    "        df_c_i = df_inverter.merge(all_predictions[prediction_horizon], how = 'inner', right_on=['date_time'], left_index=True)\n",
    "\n",
    "        x = df_c_i.copy()\n",
    "        x = x[~x.index.duplicated()]\n",
    "\n",
    "        y = regressor_dict[prediction_horizon].predict(x)\n",
    "        predictions.append(y[-1])\n",
    "\n",
    "    predict_df = pd.DataFrame(predictions).transpose()\n",
    "    predict_df.index = [df_c_i.index[-1]]\n",
    "    predict_df.index.name = 'date_time'\n",
    "    predict_df.columns = pd.MultiIndex.from_product([range(1,31)], names=['prediction_horizon (min)'])\n",
    "    \n",
    "    return predict_df\n",
    "\n",
    "predict_df = get_skycamera_predictions_apelsvoll()\n",
    "print(predict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
